{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "57912d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import pymysql\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fb423e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB_USER='root'\n",
      "DB_PASSWORD='12345678'\n",
      "DB_HOST='host.docker.internal'\n",
      "DB_PORT='3306'\n",
      "DB_NAME='sakila'\n",
      "✅ Database connection successful.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# Get DB credentials from environment variables\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASSWORD = os.getenv(\"DB_PASSWORD\")\n",
    "DB_HOST = os.getenv(\"DB_HOST\")\n",
    "DB_PORT = int(os.getenv(\"DB_PORT\") or 3306)\n",
    "DB_NAME = os.getenv(\"DB_NAME\")\n",
    "print(f\"DB_USER='{DB_USER}'\")\n",
    "print(f\"DB_PASSWORD='{DB_PASSWORD}'\")\n",
    "print(f\"DB_HOST='{DB_HOST}'\")\n",
    "print(f\"DB_PORT='{DB_PORT}'\")\n",
    "print(f\"DB_NAME='{DB_NAME}'\")\n",
    "\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "password_encoded = quote_plus(DB_PASSWORD)\n",
    "engine = create_engine(f\"mysql+pymysql://{DB_USER}:{password_encoded}@{DB_HOST}:{DB_PORT}/{DB_NAME}\")\n",
    "\n",
    "conn = engine.connect()\n",
    "\n",
    "print(\"✅ Database connection successful.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "43aec522",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataframe(df, table_name=None):\n",
    "    \"\"\"\n",
    "    Removes missing values and duplicates from a DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame to clean.\n",
    "        table_name (str): Optional, name of the table for logging purposes.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Cleaned DataFrame.\n",
    "    \"\"\"\n",
    "    original_shape = df.shape\n",
    "\n",
    "    # Drop missing values\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Drop duplicates\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    cleaned_shape = df.shape\n",
    "\n",
    "    if table_name:\n",
    "        print(f\"[{table_name}] Cleaned: {original_shape[0] - cleaned_shape[0]} rows removed\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d3e23115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dim_staff] Cleaned: 0 rows removed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>staff_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>store_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mike</td>\n",
       "      <td>Hillyer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jon</td>\n",
       "      <td>Stephens</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   staff_id first_name last_name  store_id\n",
       "0         1       Mike   Hillyer         1\n",
       "1         2        Jon  Stephens         2"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. dim_staff\n",
    "dim_staff_query = \"SELECT staff_id, first_name, last_name, store_id FROM staff\"\n",
    "dim_staff = pd.read_sql(dim_staff_query, engine)\n",
    "dim_staff = clean_dataframe(dim_staff, table_name='dim_staff')\n",
    "dim_staff.to_sql('dim_staff', con=engine, if_exists='append', index=False)\n",
    "dim_staff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "05ccfabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dim_film] Cleaned: 0 rows removed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#film\n",
    "dim_film_query = \"SELECT film_id, title, release_year, language_id FROM film\"\n",
    "dim_film = pd.read_sql(dim_film_query, engine)\n",
    "dim_film = clean_dataframe(dim_film, table_name='dim_film')\n",
    "dim_film.to_sql('dim_film', con=engine, if_exists='append', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2595e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dim_store] Cleaned: 0 rows removed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#store\n",
    "dim_store_query = \"SELECT store_id, manager_staff_id, address_id FROM store\"\n",
    "dim_store = pd.read_sql(dim_store_query, engine)\n",
    "dim_store = clean_dataframe(dim_store, table_name='dim_store')\n",
    "dim_store.to_sql('dim_store', con=engine, if_exists='append', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e8b93ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dim_date] Cleaned: 0 rows removed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "730"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. dim_date\n",
    "date_range = pd.date_range(start='2005-01-01', end='2006-12-31', freq='D')\n",
    "dim_date = pd.DataFrame({\n",
    "   'date_id': date_range.strftime('%Y%m%d').astype(int),\n",
    "   'full_date': date_range,\n",
    "   'month': date_range.month,\n",
    "   'year': date_range.year,\n",
    "})\n",
    "dim_date = clean_dataframe(dim_date, table_name='dim_date')\n",
    "dim_date.to_sql('dim_date', con=engine, if_exists='append', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "088cf69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dim_rental] Cleaned: 0 rows removed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16044"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, ensure all rental records are in dim_rental\n",
    "rentals = pd.read_sql(\n",
    "    \"SELECT rental_id, rental_date, inventory_id, customer_id FROM rental\", \n",
    "    engine\n",
    ")\n",
    "rentals = clean_dataframe(rentals, table_name='dim_rental')\n",
    "rentals.to_sql('dim_rental', con=engine, if_exists='append', index=False)\n",
    "\n",
    "# Then insert your fact table data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1fea8809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fact_daily_inventory] Cleaned: 0 rows removed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14102"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get rental and inventory data\n",
    "rental_df = pd.read_sql(\"SELECT rental_id, rental_date, inventory_id FROM rental\", engine)\n",
    "inventory_df = pd.read_sql(\"SELECT inventory_id, film_id, store_id FROM inventory\", engine)\n",
    "\n",
    "# Merge rental with inventory\n",
    "rental_inventory = rental_df.merge(inventory_df, on='inventory_id', how='inner')\n",
    "\n",
    "# Convert rental_date to date_id format (YYYYMMDD)\n",
    "rental_inventory['date_id'] = pd.to_datetime(rental_inventory['rental_date']).dt.strftime('%Y%m%d').astype(int)\n",
    "\n",
    "# Group and count rentals per film-store-date as \"inventory_count\"\n",
    "fact_daily_inventory_df = rental_inventory.groupby(\n",
    "    ['date_id', 'film_id', 'store_id']\n",
    ").size().reset_index(name='inventory_count')\n",
    "fact_daily_inventory_df = clean_dataframe(fact_daily_inventory_df, table_name='fact_daily_inventory')\n",
    "# Insert into your existing table\n",
    "fact_daily_inventory_df.to_sql('fact_daily_inventory', con=engine, if_exists='append', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a5315af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fact_monthly_payment] Cleaned: 0 rows removed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16044"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "payments = pd.read_sql(\"SELECT staff_id, rental_id, payment_date, amount FROM payment\", engine)\n",
    "payments['payment_date'] = pd.to_datetime(payments['payment_date'])\n",
    "payments['year'] = payments['payment_date'].dt.year\n",
    "payments['month'] = payments['payment_date'].dt.month\n",
    "payments['date_id'] = (payments['year'] * 10000 + payments['month'] * 100 + 1).astype(int)\n",
    "\n",
    "# Group by staff, rental, and month\n",
    "fact_monthly = payments.groupby(['staff_id', 'rental_id', 'date_id']).agg({\n",
    "   'amount': 'sum'\n",
    "}).reset_index()\n",
    "fact_monthly.rename(columns={'amount': 'monthly_payment_total'}, inplace=True)\n",
    "fact_monthly = clean_dataframe(fact_monthly, table_name='fact_monthly_payment')\n",
    "fact_monthly.to_sql('fact_monthly_payment', con=engine, if_exists='append', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
